# üéÆ Guide des Fonctionnalit√©s WaveLocalAI

Voici le d√©tail exhaustif des modules disponibles dans le Workbench **WaveLocalAI**.

---

## üîã Module 01 : Socle Hardware & Green IT

Ce module est le tableau de bord de votre audit local. Il permet de v√©rifier si la machine est pr√™te pour l'IA.

* **T√©l√©m√©trie Temps R√©el :**
    * Affiche l'usage CPU, RAM et VRAM.
    * D√©tection automatique des GPU NVIDIA et v√©rification des drivers CUDA.
* **Audit de Configuration :**
    * D√©tails techniques sur le processeur (Architecture, Cores physiques/logiques) et l'OS.
* **Green Monitor (Impact Carbone) :**
    * Estime l'impact carbone de votre session en temps r√©el (gCO2eq).
    * **M√©thodologie :** Bas√©e sur la librairie **CodeCarbon**.
    * **Calcul :** (TDP Mat√©riel + PUE Datacenter) √ó Mix √âlectrique France (ou local).
    * **Mode Low Power :** Si aucun GPU n'est d√©tect√©, l'estimation s'adapte automatiquement √† une consommation CPU-only.

---

## üß† Module 02 : Inf√©rence & Arena

Ce module est le c≈ìur de l'interaction avec les SLM (Small Language Models). Il est divis√© en trois onglets pour s√©parer les usages.

### üí¨ Onglet 1 : Chat Interactif (Conversation)
Une interface type "ChatGPT" pour dialoguer librement avec vos mod√®les.
* **M√©moire Contextuelle :** Le mod√®le se souvient des √©changes pr√©c√©dents de la session.
* **Streaming Fluide :** La r√©ponse s'affiche mot √† mot (token par token) pour un ressenti temps r√©el.
* **Param√®tres :**
    * **Temp√©rature :** Ajustable de 0.0 (Factuel/Code) √† 1.0 (Cr√©atif).
    * **Mode Hybride :** Interface pr√©par√©e pour le basculement entre Local (Ollama) et Cloud (Mistral API).

### üß™ Onglet 2 : Labo de Tests (Benchmarks)
Un environnement "Stateless" (sans m√©moire) pour tester la performance brute sur des t√¢ches pr√©cises.
* **Sc√©narios Pr√©d√©finis :** Biblioth√®que de prompts optimis√©s (Traduction Technique, Extraction JSON, Coding Assistant, Raisonnement).
* **Configuration Avanc√©e :**
    * **System Prompt √âditable :** Permet de modifier radicalement le comportement du mod√®le (ex: "Tu es un expert JSON strict").
    * **M√©triques Techniques :** Affichage post-inf√©rence du d√©bit (Tokens/s), de la latence (s) et du temps de chargement.

### ‚öôÔ∏è Onglet 3 : Gestionnaire de Mod√®les (Model Manager)
Une interface d'administration avanc√©e pour g√©rer votre biblioth√®que locale Ollama.
* **Catalogue Enrichi :**
    * Tableau d√©taill√© : Nom, √âditeur, Taille (GB), Param√®tres (Totaux/Actifs), Contexte (ex: 32k, 128k).
    * **Smart Names :** Conversion automatique des tags techniques illisibles (ex: `hf.co/...`) en noms clairs.
    * **Liens Documentation :** Acc√®s direct aux fiches mod√®les (HuggingFace/Mistral) depuis l'interface.
* **Filtres & Recherche :**
    * **Filtre par Langue :** Trouvez instantan√©ment les mod√®les supportant le Fran√ßais, le Code, etc.
* **Installation Simplifi√©e :**
    * **Menu d√©roulant :** Suggestions cur√©es par Wavestone (Qwen, Mistral, Llama, Gemma, Granite, etc.).
    * **Feedback Visuel :** Barre de progression temps r√©el lors du t√©l√©chargement (Pull).
    * **Saisie Manuelle :** Champ libre pour t√©l√©charger n'importe quel mod√®le du registre Ollama.

---

## üìö Module 03 : RAG Knowledge (Base Documentaire)

Ce module permet de discuter avec vos propres documents (PDF, TXT) sans que les donn√©es ne quittent votre machine.

### üì• Ingestion & Vectorisation
* **Support Multi-formats :** Upload de fichiers PDF, TXT, MD.
* **Moteur Vectoriel Local :**
    * Utilise **ChromaDB** pour le stockage persistant (les donn√©es restent apr√®s red√©marrage).
    * Utilise le mod√®le d'embedding **`all-MiniLM-L6-v2`** optimis√© pour CPU (rapide et l√©ger).
* **Introspection :** Tableau de bord affichant le nombre exact de "chunks" (morceaux de texte) en base et la liste des fichiers sources index√©s.

### üîé Recherche & Observabilit√©
Contrairement aux bo√Ætes noires, ce module montre tout :
* **Step-by-Step Debugging :** Chronom√©trage pr√©cis de chaque √©tape :
    1.  *Retrieval :* Temps de recherche dans la base vectorielle.
    2.  *Context Assembly :* Temps de pr√©paration du prompt.
    3.  *G√©n√©ration :* Mesure du **TTFT** (Temps avant le 1er token) et du d√©bit de g√©n√©ration.
* **Transparence des Sources :** Affichage des extraits de texte exacts utilis√©s par l'IA pour g√©n√©rer sa r√©ponse (lutte contre les hallucinations).

---

## ü§ñ Module 04 : Agent Lab (Automation)

Ce module transforme l'IA en agent autonome capable d'agir via des outils, bas√© sur l'architecture **LangGraph**.

### üõ†Ô∏è Outils Disponibles (Tools)
L'agent a acc√®s √† des fonctions Python s√©curis√©es :
1.  **üïí get_current_time :** Acc√®s √† l'horloge syst√®me (ce que les LLM ne peuvent pas faire seuls).
2.  **üßÆ calculator :** Ex√©cution de calculs math√©matiques exacts.
3.  **üè¢ search_wavestone_internal :** Moteur de recherche simul√© (Base de connaissance RH/Projets) avec gestion intelligente des fautes de frappe et accents.

### üß† Capacit√©s Cognitives
* **Filtrage Intelligent :** L'interface ne propose que les mod√®les capables de faire du "Tool Calling" (ex: Qwen 2.5, Mistral) pour √©viter les erreurs.
* **Pens√©e Visible (Chain of Thought) :**
    * Visualisation du raisonnement interne de l'agent (balises `<think>`).
    * Affichage des logs d'ex√©cution : Quel outil est appel√© ? Avec quels arguments ? Quel est le r√©sultat ?
* **Mode ReAct :** L'agent suit la boucle *Raisonner -> Agir -> Observer -> Conclure*.

---
*D√©velopp√© pour Wavestone - Architecture Local First.*