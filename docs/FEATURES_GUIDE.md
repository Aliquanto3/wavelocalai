# ğŸ® Guide des FonctionnalitÃ©s WaveLocalAI

Voici le dÃ©tail exhaustif des modules disponibles dans le Workbench **WaveLocalAI**.

---

## ğŸ”‹ Module 01 : Socle Hardware & Green IT

Ce module est le tableau de bord de votre audit local. Il permet de vÃ©rifier si la machine est prÃªte pour l'IA.

* **TÃ©lÃ©mÃ©trie Temps RÃ©el :**
    * Affiche l'usage CPU, RAM et VRAM.
    * DÃ©tection automatique des GPU NVIDIA et vÃ©rification des drivers CUDA.
* **Audit de Configuration :**
    * DÃ©tails techniques sur le processeur (Architecture, Cores physiques/logiques) et l'OS.
* **Green Monitor (Impact Carbone) :**
    * Estime l'impact carbone de votre session en temps rÃ©el (gCO2eq).
    * **MÃ©thodologie :** BasÃ©e sur la librairie **CodeCarbon**.
    * **Calcul :** (TDP MatÃ©riel + PUE Datacenter) Ã— Mix Ã‰lectrique France (ou local).
    * **Mode Low Power :** Si aucun GPU n'est dÃ©tectÃ©, l'estimation s'adapte automatiquement Ã  une consommation CPU-only.

---

## ğŸ§  Module 02 : InfÃ©rence & Arena

Ce module est le cÅ“ur de l'interaction avec les SLM (Small Language Models). Il est divisÃ© en trois onglets pour sÃ©parer les usages.

### ğŸ’¬ Onglet 1 : Chat Interactif (Conversation)
Une interface type "ChatGPT" pour dialoguer librement avec vos modÃ¨les.
* **MÃ©moire Contextuelle :** Le modÃ¨le se souvient des Ã©changes prÃ©cÃ©dents de la session.
* **Streaming Fluide :** La rÃ©ponse s'affiche mot Ã  mot (token par token) pour un ressenti temps rÃ©el.
* **ParamÃ¨tres :**
    * **TempÃ©rature :** Ajustable de 0.0 (Factuel/Code) Ã  1.0 (CrÃ©atif).
    * **Mode Hybride :** Interface prÃ©parÃ©e pour le basculement entre Local (Ollama) et Cloud (Mistral API).

### ğŸ§ª Onglet 2 : Labo de Tests (Benchmarks)
Un environnement "Stateless" (sans mÃ©moire) pour tester la performance brute sur des tÃ¢ches prÃ©cises.
* **ScÃ©narios PrÃ©dÃ©finis :** BibliothÃ¨que de prompts optimisÃ©s (Traduction Technique, Extraction JSON, Coding Assistant, Raisonnement).
* **Configuration AvancÃ©e :**
    * **System Prompt Ã‰ditable :** Permet de modifier radicalement le comportement du modÃ¨le (ex: "Tu es un expert JSON strict").
    * **MÃ©triques Techniques :** Affichage post-infÃ©rence du dÃ©bit (Tokens/s), de la latence (s) et du temps de chargement.

### âš™ï¸ Onglet 3 : Gestionnaire de ModÃ¨les (Model Manager)
Une interface d'administration avancÃ©e pour gÃ©rer votre bibliothÃ¨que locale Ollama.
* **Catalogue Enrichi :**
    * Tableau dÃ©taillÃ© : Nom, Ã‰diteur, Taille (GB), ParamÃ¨tres (Totaux/Actifs), Contexte (ex: 32k, 128k).
    * **Smart Names :** Conversion automatique des tags techniques illisibles (ex: `hf.co/...`) en noms clairs.
    * **Liens Documentation :** AccÃ¨s direct aux fiches modÃ¨les (HuggingFace/Mistral) depuis l'interface.
* **Filtres & Recherche :**
    * **Filtre par Langue :** Trouvez instantanÃ©ment les modÃ¨les supportant le FranÃ§ais, le Code, etc.
* **Installation SimplifiÃ©e :**
    * **Menu dÃ©roulant :** Suggestions curÃ©es par Wavestone (Qwen, Mistral, Llama, Gemma, Granite, etc.).
    * **Feedback Visuel :** Barre de progression temps rÃ©el lors du tÃ©lÃ©chargement (Pull).
    * **Saisie Manuelle :** Champ libre pour tÃ©lÃ©charger n'importe quel modÃ¨le du registre Ollama.

---

## ğŸ“š Module 03 : RAG Knowledge (Base Documentaire)

Ce module permet de discuter avec vos propres documents (PDF, TXT) sans que les donnÃ©es ne quittent votre machine.

### ğŸ“¥ Ingestion & Vectorisation
* **Support Multi-formats :** Upload de fichiers PDF, TXT, MD.
* **Moteur Vectoriel Local :**
    * Utilise **ChromaDB** pour le stockage persistant (les donnÃ©es restent aprÃ¨s redÃ©marrage).
    * Utilise le modÃ¨le d'embedding **`all-MiniLM-L6-v2`** optimisÃ© pour CPU (rapide et lÃ©ger).
* **Introspection :** Tableau de bord affichant le nombre exact de "chunks" (morceaux de texte) en base et la liste des fichiers sources indexÃ©s.

### ğŸ” Recherche & ObservabilitÃ©
Contrairement aux boÃ®tes noires, ce module montre tout :
* **Step-by-Step Debugging :** ChronomÃ©trage prÃ©cis de chaque Ã©tape :
    1.  *Retrieval :* Temps de recherche dans la base vectorielle.
    2.  *Context Assembly :* Temps de prÃ©paration du prompt.
    3.  *GÃ©nÃ©ration :* Mesure du **TTFT** (Temps avant le 1er token) et du dÃ©bit de gÃ©nÃ©ration.
* **Transparence des Sources :** Affichage des extraits de texte exacts utilisÃ©s par l'IA pour gÃ©nÃ©rer sa rÃ©ponse (lutte contre les hallucinations).

---

## ğŸ¤– Module 04 : Agent Lab (Automation)

Ce module transforme l'IA en agent autonome capable d'agir via des outils, basÃ© sur l'architecture **LangGraph**.

### ğŸ› ï¸ Outils Disponibles (Tools)
L'agent a accÃ¨s Ã  des fonctions Python sÃ©curisÃ©es :
1.  **ğŸ•’ get_current_time :** AccÃ¨s Ã  l'horloge systÃ¨me (ce que les LLM ne peuvent pas faire seuls).
2.  **ğŸ§® calculator :** ExÃ©cution de calculs mathÃ©matiques exacts.
3.  **ğŸ¢ search_wavestone_internal :** Moteur de recherche simulÃ© (Base de connaissance RH/Projets) avec gestion intelligente des fautes de frappe et accents.

### ğŸ§  CapacitÃ©s Cognitives
* **Filtrage Intelligent :** L'interface ne propose que les modÃ¨les capables de faire du "Tool Calling" (ex: Qwen 2.5, Mistral) pour Ã©viter les erreurs.
* **PensÃ©e Visible (Chain of Thought) :**
    * Visualisation du raisonnement interne de l'agent (balises `<think>`).
    * Affichage des logs d'exÃ©cution : Quel outil est appelÃ© ? Avec quels arguments ? Quel est le rÃ©sultat ?
* **Mode ReAct :** L'agent suit la boucle *Raisonner -> Agir -> Observer -> Conclure*.

## MISE Ã€ JOUR

### ğŸ› ï¸ Outils Disponibles (Tools)
L'agent a maintenant accÃ¨s Ã  **9 outils** (anciennement 3) :

**SystÃ¨me :**
- ğŸ•’ Time
- ğŸ’» System Monitor

**Calcul :**
- ğŸ§® Calculator

**DonnÃ©es :**
- ğŸ“Š CSV Analyzer
- ğŸ¢ Wavestone Search

**Communication :**
- ğŸ“§ Email Sender

**GÃ©nÃ©ration :**
- ğŸ“ Document Generator (DOCX)
- ğŸ“ˆ Chart Generator (PNG)
- ğŸ“„ Markdown Report

Voir [AGENT_TOOLS.md](AGENT_TOOLS.md) pour la documentation complÃ¨te.

---
*DÃ©veloppÃ© pour Wavestone - Architecture Local First.*
