import logging
import sys
from pathlib import Path

import psutil
import streamlit as st

# --- IMPORT SSOT ---
try:
    from src.core.green_monitor import GreenTracker
except ImportError:
    GreenTracker = None

# --- CONFIGURATION INITIALE ---
st.set_page_config(
    page_title="WaveLocalAI | GenAI Souveraine",
    page_icon="üåä",
    layout="wide",
    initial_sidebar_state="expanded",
)

# --- SETUP PATH & LOGGING ---
root_path = Path(__file__).parent.parent.parent
if str(root_path) not in sys.path:
    sys.path.append(str(root_path))

logger = logging.getLogger(__name__)

# --- GESTION √âTAT (Cloud vs Local) ---
if "cloud_enabled" not in st.session_state:
    st.session_state.cloud_enabled = True

# --- INIT TRACKER (Singleton) ---
if "tracker" not in st.session_state and GreenTracker:
    st.session_state.tracker = GreenTracker(project_name="wavelocal_session")
    st.session_state.tracker.start()
    st.session_state.tracking_active = True


# ==========================================
# NOUVEAU CALLBACK POUR SYNCHRONISATION
# ==========================================
def update_cloud_state():
    """
    Callback ex√©cut√© imm√©diatement apr√®s le changement de st.toggle.
    Ceci garantit que la session state est mise √† jour AVANT le rerun,
    √©vitant l'effet de d√©synchronisation.
    """
    # La valeur du toggle est pass√©e via la cl√© 'global_cloud_toggle'
    st.session_state.cloud_enabled = st.session_state.global_cloud_toggle
    # Le rerun n'est pas n√©cessaire ici car Streamlit le fera apr√®s le callback,
    # mais la mise √† jour imm√©diate est cruciale.


def get_system_health():
    """Petit check rapide pour l'accueil."""
    cpu = psutil.cpu_percent(interval=0.1)
    mem = psutil.virtual_memory().percent
    return cpu, mem


def main():
    # --- HERO SECTION ---
    st.title("üåä WaveLocalAI Workbench")
    st.markdown(
        "### Le d√©monstrateur d'IA G√©n√©rative **Souveraine**, **Frugale** et **S√©curis√©e**."
    )

    st.divider()

    # --- KPI STATUS BAR (DYNAMIQUE) ---
    cpu, mem = get_system_health()

    # Logique d'affichage Confidentialit√©
    # Elle lit directement la st.session_state mise √† jour par le callback
    if st.session_state.cloud_enabled:
        privacy_label = "Mode Hybride ‚òÅÔ∏è"
        privacy_val = "API Active"
        privacy_help = "‚ö†Ô∏è Attention : Les mod√®les Cloud (Mistral/OpenAI) sont activ√©s. Les donn√©es envoy√©es √† ces mod√®les quittent votre infrastructure."
    else:
        privacy_label = "Confidentialit√©"
        privacy_val = "100% Local üîí"
        privacy_help = "‚úÖ S√©curis√© : Tous les mod√®les tournent sur cette machine (Ollama). Aucune donn√©e ne sort."

    col_kpi1, col_kpi2, col_kpi3, col_kpi4 = st.columns(4)

    with col_kpi1:
        st.metric("Syst√®me", "Op√©rationnel üü¢", help="Tous les services sont actifs")
    with col_kpi2:
        st.metric("Charge CPU", f"{cpu}%", help="Charge actuelle du processeur")
    with col_kpi3:
        st.metric("M√©moire RAM", f"{mem}%", help="Occupation de la m√©moire vive")
    with col_kpi4:
        st.metric(privacy_label, privacy_val, help=privacy_help)

    st.divider()

    # --- NAVIGATION GRID (2x2) ---
    st.subheader("üìç Modules d'exploration")

    row1_1, row1_2 = st.columns(2)
    row2_1, row2_2 = st.columns(2)

    # CARD 1 : HARDWARE
    with row1_1, st.container(border=True):
        c_ico, c_txt = st.columns([1, 5])
        with c_ico:
            st.markdown("# üîã")
        with c_txt:
            st.markdown("#### 01. Cockpit GreenOps")
            st.caption(
                "Monitoring temps r√©el de la consommation √©nerg√©tique et des ressources machine."
            )
            st.page_link("pages/01_Socle_Hardware.py", label="Acc√©der au Cockpit", icon="üìä")

    # CARD 2 : INFERENCE
    with row1_2, st.container(border=True):
        c_ico, c_txt = st.columns([1, 5])
        with c_ico:
            st.markdown("# üß†")
        with c_txt:
            st.markdown("#### 02. Inf√©rence & Arena")
            st.caption(
                "Benchmark et chat avec des mod√®les SLM quantiz√©s (Llama 3, Mistral, Gemma)."
            )
            st.page_link("pages/02_Inference_Arena.py", label="Entrer dans l'Ar√®ne", icon="‚öîÔ∏è")

    # CARD 3 : RAG
    with row2_1, st.container(border=True):
        c_ico, c_txt = st.columns([1, 5])
        with c_ico:
            st.markdown("# üìö")
        with c_txt:
            st.markdown("#### 03. Base de Connaissance (RAG)")
            st.caption("Interrogation documentaire s√©curis√©e sans fuite de donn√©es.")
            st.page_link("pages/03_RAG_Knowledge.py", label="G√©rer les Documents", icon="üìÇ")

    # CARD 4 : AGENTS
    with row2_2, st.container(border=True):
        c_ico, c_txt = st.columns([1, 5])
        with c_ico:
            st.markdown("# ü§ñ")
        with c_txt:
            st.markdown("#### 04. Agents Autonomes")
            st.caption("Orchestration d'√©quipes d'agents pour des t√¢ches complexes (CrewAI).")
            st.page_link("pages/04_Agent_Lab.py", label="Lancer les Agents", icon="üöÄ")

    # --- FOOTER ---
    st.markdown("---")

    # Toggle global pour contr√¥ler la confidentialit√© depuis l'accueil
    c_toggle, c_copyright = st.columns([1, 3])
    with c_toggle:
        # 1. Utilisation de on_change=update_cloud_state
        # 2. Key simple pour le lire dans le callback
        st.session_state.cloud_enabled = st.toggle(
            "Autoriser les API Cloud (Mistral/OpenAI)",
            value=st.session_state.cloud_enabled,
            key="global_cloud_toggle",
            on_change=update_cloud_state,  # L'√©l√©ment cl√©
            help="D√©sactivez pour forcer un mode strictement local sur toutes les pages.",
        )
        if not st.session_state.cloud_enabled:
            st.caption("üîí Mode Local Strict activ√©")

    with c_copyright:
        st.caption("¬© 2025 WaveLocalAI - Wavestone Tech Lab | v2.0.0 (Stable)")


if __name__ == "__main__":
    main()
