import logging

import psutil

from src.core.config import SYSTEM_RAM_BUFFER_GB
from src.core.models_db import MODELS_DB, get_friendly_name_from_tag

# Logging
logger = logging.getLogger(__name__)


class ResourceCheckResult:
    def __init__(
        self,
        allowed: bool,
        message: str,
        ram_required_gb: float = 0.0,
        ram_available_gb: float = 0.0,
    ):
        self.allowed = allowed
        self.message = message
        self.ram_required_gb = ram_required_gb
        self.ram_available_gb = ram_available_gb


class ResourceManager:
    """
    Garde-fou pour la gestion des ressources syst√®me (RAM).
    Emp√™che le lancement de processus si la RAM est insuffisante.
    """

    @staticmethod
    def get_available_ram_gb() -> float:
        """Retourne la RAM disponible r√©elle en GB."""
        return psutil.virtual_memory().available / (1024**3)

    @staticmethod
    def estimate_model_ram(model_tag: str) -> float:
        """
        Estime la RAM n√©cessaire pour un mod√®le sp√©cifique.
        Utilise les donn√©es empiriques de models.json si disponibles (audit),
        sinon fait une estimation heuristique bas√©e sur la taille du fichier.

        Returns:
            float: RAM estim√©e en GB. Retourne 0.0 pour les mod√®les API.
        """
        friendly_name = get_friendly_name_from_tag(model_tag)
        info = MODELS_DB.get(friendly_name)

        if info:
            # ‚úÖ NOUVEAU : V√©rification si le mod√®le est de type API
            if info.get("type") == "api":
                return 0.0  # Les mod√®les API ne consomment pas de RAM locale

            # 1. Priorit√© : Donn√©e d'audit r√©elle (stress test)
            benchmark_stats = info.get("benchmark_stats", {})
            if benchmark_stats and "ram_usage_gb" in benchmark_stats:
                # On ajoute 10% de marge de s√©curit√© sur la valeur mesur√©e
                return float(benchmark_stats["ram_usage_gb"]) * 1.1

            # 2. Fallback : Taille du fichier sur disque (approximation grossi√®re pour GGUF)
            # Pour un GGUF charg√© en RAM, c'est souvent taille_disque + 0.5/1GB de overhead
            if "size_gb" in info:
                try:
                    size_str = info["size_gb"].replace(" GB", "")
                    return float(size_str) + 1.0
                except ValueError:
                    pass

        # 3. Dernier recours : Valeur par d√©faut conservatrice
        return 4.0

    @classmethod
    def free_ollama_memory(cls) -> float:
        """
        Lib√®re la m√©moire Ollama en d√©chargeant les mod√®les inactifs.

        Returns:
            float: RAM lib√©r√©e en GB
        """
        try:
            import gc

            import ollama

            ram_before = cls.get_available_ram_gb()

            # Arr√™t des mod√®les en cours
            running = ollama.ps()
            if running.get("models"):
                logger.info(f"D√©chargement de {len(running['models'])} mod√®le(s)...")
                # Note : Ollama d√©charge automatiquement apr√®s timeout
                # On force juste le garbage collection Python

            gc.collect()

            ram_after = cls.get_available_ram_gb()
            freed = ram_after - ram_before

            if freed > 0:
                logger.info(f"‚úÖ {freed:.2f} GB de RAM lib√©r√©e")

            return freed

        except Exception as e:
            logger.error(f"Erreur lors de la lib√©ration m√©moire : {e}")
            return 0.0

    @classmethod
    def check_resources(
        cls, model_tag: str, n_instances: int = 1, auto_free: bool = True
    ) -> ResourceCheckResult:
        """
        V√©rifie si le syst√®me a assez de ressources pour lancer N instances du mod√®le.

        Args:
            model_tag: Tag du mod√®le
            n_instances: Nombre d'agents simultan√©s pr√©vus
            auto_free: Si True, tente de lib√©rer de la RAM si insuffisante

        Returns:
            ResourceCheckResult: Verdict (Autoris√©/Refus√©) avec d√©tails.
        """
        # 1. Estimation du besoin
        unit_ram = cls.estimate_model_ram(model_tag)
        total_ram_needed = unit_ram * n_instances

        # 2. V√©rification disponibilit√©
        available_ram = cls.get_available_ram_gb()
        safe_available_ram = available_ram - SYSTEM_RAM_BUFFER_GB

        # 3. Si insuffisant ET auto_free activ√©, tenter de lib√©rer
        if safe_available_ram < total_ram_needed and auto_free and unit_ram > 0:
            logger.warning(
                f"RAM insuffisante ({safe_available_ram:.2f}GB < {total_ram_needed:.2f}GB). Tentative de lib√©ration..."
            )
            freed = cls.free_ollama_memory()

            # R√©√©valuation apr√®s lib√©ration
            available_ram = cls.get_available_ram_gb()
            safe_available_ram = available_ram - SYSTEM_RAM_BUFFER_GB

            if freed > 0:
                logger.info(f"Nouvelle RAM disponible : {safe_available_ram:.2f}GB")

        # 4. Verdict final
        if safe_available_ram >= total_ram_needed:
            msg = (
                f"‚úÖ Ressources suffisantes. "
                f"Besoin: {total_ram_needed:.2f}GB ({n_instances}x {unit_ram:.2f}GB). "
                f"Dispo (safe): {safe_available_ram:.2f}GB."
            )
            logger.info(msg)
            return ResourceCheckResult(True, msg, total_ram_needed, available_ram)
        else:
            msg = (
                f"‚õî RAM Insuffisante ! Risque de crash. "
                f"Besoin: {total_ram_needed:.2f}GB. "
                f"Dispo r√©elle: {available_ram:.2f}GB (Buffer s√©cu {SYSTEM_RAM_BUFFER_GB}GB d√©duit). "
                f"üí° Essayez de lib√©rer la RAM via le bouton dans la sidebar."
            )
            logger.warning(msg)
            return ResourceCheckResult(False, msg, total_ram_needed, available_ram)
