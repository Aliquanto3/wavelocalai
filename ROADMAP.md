# Roadmap du Projet

Ce document liste les fonctionnalit√©s pr√©vues, class√©es par priorit√© strat√©gique.

## üöÄ Court Terme : Consolidation Benchmark & √âvaluation
L'objectif est de renforcer la capacit√© de l'outil √† comparer objectivement les mod√®les (LLM-as-a-Judge, M√©triques).

- [ ] **Script de Benchmark automatis√©** : Tester tous les mod√®les sur un prompt donn√©, enregistrer inputs/outputs et m√©triques (latence, tokens/s).
- [ ] **Interface "Arena" (Comparaison)** : Nouvel onglet permettant de s√©lectionner N mod√®les, les ex√©cuter en parall√®le sur un prompt et afficher les r√©sultats c√¥te √† c√¥te.
- [ ] **√âvaluation RAG** : Int√©gration de pipelines d'√©valuation (Ragas ou Giskard) pour scorer la qualit√© des r√©ponses sur documents.
- [ ] **Fichiers de test RAG** : Fournir un set de documents par d√©faut pour faciliter les d√©mos et tests imm√©diats.

## üõ† Moyen Terme : Industrialisation & UX
Am√©liorer la robustesse et l'exp√©rience utilisateur.

- [ ] **Impact Environnemental Avanc√©** : Distinction claire entre l'impact calcul√© (Local/CodeCarbon) et l'impact estim√© (Cloud/API) avec ventilation par scope.
- [ ] **Refonte UX** : Condenser l'interface (sidebar, affichage des m√©triques) pour plus de densit√© d'information.
- [ ] **Dockerisation** : G√©n√©ration d'une image Docker pour d√©ploiement facile.

## üîÆ Futur / Exploration
Fonctionnalit√©s avanc√©es d'orchestration.
- [ ] **LLM Council** : Syst√®me de vote entre mod√®les pour d√©terminer la meilleure r√©ponse (synth√®se).

## ‚úÖ Compl√©t√© (D√©cembre 2025)

- [x] **Int√©gration Mistral API** : Support complet des mod√®les Mistral
- [x] **Mode Multi-agents** : Impl√©mentation CrewAI avec 8+ workflows
- [x] **9 outils agents** : Email, CSV, DOCX, Charts, Markdown, Monitor
- [x] **D√©tection unifi√©e** : model_detector.py comme source unique

---
*Derni√®re mise √† jour : 13/12/2025*
