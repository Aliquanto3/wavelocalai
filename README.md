# ğŸŒŠ WaveLocalAI

**Workbench de dÃ©monstration d'IA locale et responsable**

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.32+-red.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Tests](https://img.shields.io/badge/tests-118%20passed-brightgreen.svg)](#)
[![Coverage](https://img.shields.io/badge/coverage-86.5%25-brightgreen.svg)](#)

> ğŸ’¡ *DÃ©monstration interactive des Small Language Models (SLM) pour Wavestone : Performance, Green IT et SouverainetÃ© des DonnÃ©es.*

---

## ğŸ¯ Vision & Objectifs

WaveLocalAI est un **proof of concept** conÃ§u pour :

1. **ğŸ”’ SouverainetÃ© des DonnÃ©es** : Tout reste sur votre machine (0 appel API par dÃ©faut)
2. **ğŸŒ± Green IT** : Mesure de l'impact carbone temps rÃ©el (CodeCarbon)
3. **ğŸ“Š ComparabilitÃ©** : Benchmarks objectifs entre modÃ¨les locaux et cloud
4. **ğŸ¤– Autonomie** : Agents IA avec outils (calculatrice, recherche, gÃ©nÃ©ration de documents)

---

## âš¡ Quick Start

### PrÃ©requis

- **Python 3.10+**
- **Ollama** : [TÃ©lÃ©charger ici](https://ollama.com/download)
- *Optionnel :* ClÃ© API Mistral pour comparaison Cloud

### Installation (5 min)

```bash
# 1. Cloner le projet
git clone https://github.com/Aliquanto3/wavelocalai.git
cd wavelocalai

# 2. CrÃ©er l'environnement virtuel
python -m venv .venv

# 3. Installer les dÃ©pendances (Windows)
.venv\Scripts\python -m pip install -r requirements.txt

# Mac/Linux
.venv/bin/python -m pip install -r requirements.txt

# 4. Configurer (optionnel)
cp .env.example .env
# Ã‰diter .env pour ajouter MISTRAL_API_KEY si souhaitÃ©

# 5. Installer les outils agents (nouveaux)
.venv\Scripts\python -m pip install python-docx matplotlib openpyxl xlrd langchain-mistralai

# 6. TÃ©lÃ©charger un modÃ¨le local
ollama pull qwen2.5:1.5b

# 7. Lancer l'application
.venv\Scripts\python -m streamlit run src/app/Accueil.py
```

ğŸ‰ **L'interface s'ouvre sur http://localhost:8501**

---

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| [Installation](docs/TROUBLESHOOT.md) | Guide dÃ©taillÃ© et rÃ©solution d'erreurs |
| [Architecture](docs/ARCHITECTURE.md) | Structure technique du code |
| [FonctionnalitÃ©s](docs/FEATURES_GUIDE.md) | Guide utilisateur complet |
| [Configuration](docs/CONFIGURATION.md) | Variables d'environnement |
| [Contributing](CONTRIBUTING.md) | Guide de contribution |
| [Agent Tools](docs/AGENT_TOOLS.md) | **NOUVEAU** - Documentation des 9 outils agents |

---

## ğŸ¯ FonctionnalitÃ©s

### ğŸ“‹ Module 1 : Socle Hardware & Green IT
- Audit matÃ©riel (CPU, RAM, GPU)
- Monitoring carbone temps rÃ©el
- Dashboard de tÃ©lÃ©mÃ©trie

### ğŸ§  Module 2 : InfÃ©rence & Arena
- **Chat Libre** : Conversation avec mÃ©moire contextuelle
- **Labo de Tests** : Benchmarks techniques (tokens/s, latence)
- **Model Manager** : TÃ©lÃ©chargement et gestion des modÃ¨les Ollama
- **Support API Mistral** : Comparaison Local vs Cloud

### ğŸ“š Module 3 : RAG Knowledge
- **Architecture AvancÃ©e** : Supporte Naive, HyDE et Self-RAG.
- **EvalOps IntÃ©grÃ©** : Benchmark automatique "LLM-as-a-Judge" (Scores FidÃ©litÃ©/Pertinence).
- **Green RAG** : Mesure de l'impact CO2/RAM par requÃªte.
- **Multi-ModÃ¨les** : Choix dynamique des Embeddings et Rerankers (Local SOTA).

### ğŸ¤– Module 4 : Agent Lab â­ **NOUVEAU**
**Architecture rÃ©novÃ©e avec support complet des modÃ¨les API**

#### **Mode Solo (Agent Autonome)**
- **9 outils disponibles** (anciennement 3) :
  - ğŸ•’ **Time** : Heure systÃ¨me
  - ğŸ§® **Calculator** : Calculs mathÃ©matiques sÃ©curisÃ©s
  - ğŸ¢ **Wavestone Search** : Recherche interne simulÃ©e
  - ğŸ“§ **Email Sender** : Envoi d'emails via SMTP
  - ğŸ“Š **CSV Analyzer** : Analyse de donnÃ©es (Pandas)
  - ğŸ“ **Document Generator** : CrÃ©ation de fichiers DOCX
  - ğŸ“ˆ **Chart Generator** : GÃ©nÃ©ration de graphiques PNG
  - ğŸ“„ **Markdown Report** : Rapports structurÃ©s MD
  - ğŸ’» **System Monitor** : MÃ©triques CPU/RAM/Disque

- **SÃ©lection dynamique d'outils** : Activez uniquement les outils nÃ©cessaires
- **BibliothÃ¨que de 15+ prompts prÃ©dÃ©finis** organisÃ©s par catÃ©gorie
- **Support modÃ¨les API** : Mistral Large, Devstral, Ministral
- **Visualisation du raisonnement** : Chain of Thought visible

#### **Mode Crew (Multi-Agents)**
- **Workflows prÃ©dÃ©finis** : 8+ scÃ©narios d'Ã©quipes optimisÃ©es
- **Composition flexible** : Jusqu'Ã  N agents avec rÃ´les, objectifs et backstories
- **SÃ©lection d'outils par agent** : Chaque agent a ses propres outils
- **Mix Local/API** : Combinez modÃ¨les locaux et cloud dans une mÃªme Ã©quipe
- **Collaboration avancÃ©e** : DÃ©lÃ©gation et communication inter-agents
- **Logs nettoyÃ©s** : Historique complet avec codes ANSI supprimÃ©s

**Exemples de workflows Crew :**
- ğŸ“Š Ã‰tude concurrentielle (3 agents : Chercheur, Analyste, RÃ©dacteur)
- ğŸ”¬ Pipeline d'analyse de donnÃ©es complÃ¨te
- ğŸ“ˆ Rapport exÃ©cutif automatisÃ© (4 agents)
- ğŸ¯ Benchmark FinOps/GreenOps comparatif

---

## ğŸ§ª Tests & QualitÃ©

```bash
# Lancer les tests unitaires
pytest tests/unit/ -v

# Tests avec couverture
pytest tests/ --cov=src.core --cov-report=html

# Linting
ruff check src/ tests/
black --check src/ tests/
```

**MÃ©triques actuelles :**
- âœ… **118 tests** (100 unitaires, 18 intÃ©gration)
- âœ… **86.5% de couverture**
- âœ… **0 vulnÃ©rabilitÃ©** critique

**Nouveaux tests :**
- Tests unitaires pour les 9 outils agents
- Tests d'intÃ©gration Agent Solo/Crew
- Tests de dÃ©tection de modÃ¨les API vs Local
- Validation des workflows prÃ©dÃ©finis

---

## ğŸ†• NouveautÃ©s Principales (DÃ©cembre 2024)

### ğŸ”§ Architecture Modulaire des Outils
- **Module `model_detector.py`** : Source unique de vÃ©ritÃ© pour dÃ©tecter API vs Local
- **Module `agent_tools.py`** : 9 outils avec mÃ©tadonnÃ©es complÃ¨tes
- **Pattern standardisÃ©** : Fonction pure + wrapper LangChain + mÃ©tadonnÃ©es UI

### ğŸ¨ Refonte ComplÃ¨te des Interfaces
- **Solo** : SÃ©lection d'outils + bibliothÃ¨que de prompts + guide intÃ©grÃ©
- **Crew** : Workflows prÃ©dÃ©finis + multiselect outils par agent + logs amÃ©liorÃ©s
- **CohÃ©rence visuelle** : Ã‰mojis ğŸ  Local / ğŸŒ API dans tous les logs

### ğŸŒ Support API UnifiÃ©
- **Mistral Large 3** (675B paramÃ¨tres, 41B actifs)
- **Devstral 2** (123B - Coding & Agents)
- **Ministral 3** (14B/8B/3B - Edge-friendly)
- **Mistral Small 3.2** (24B - General purpose)
- DÃ©tection automatique via `data/models.json`

### ğŸ“Š Gestion des Fichiers GÃ©nÃ©rÃ©s
- Tous les fichiers crÃ©Ã©s par les outils â†’ `outputs/`
- Nomenclature standardisÃ©e : `{type}_{timestamp}.{ext}`
- Support des images dans le chat (affichage direct des PNG/JPG)

---

## ğŸ”§ Configuration AvancÃ©e

### Variables d'Environnement (.env)

```bash
# === ClÃ©s API (Optionnel) ===
MISTRAL_API_KEY=sk-proj-xxxxx  # Pour modÃ¨les Mistral API

# === SMTP pour Email Tool (Optionnel) ===
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=votre-email@gmail.com
SMTP_PASSWORD=votre-app-password

# === Green IT ===
WAVELOCAL_COUNTRY_ISO=FRA  # FRA, DEU, USA...
WAVELOCAL_PUE=1.0          # 1.0=Local, 1.4=Datacenter

# === RAG ===
WAVELOCAL_EMBEDDING_MODEL=all-MiniLM-L6-v2

# === Chemins ===
WAVELOCAL_DATA_DIR=./data
WAVELOCAL_LOGS_DIR=./data/logs
```

### Ajout d'un Nouveau ModÃ¨le

Ã‰diter `data/models.json` :

```json
{
    "Mon Nouveau ModÃ¨le": {
        "ollama_tag": "mon-modele:latest",
        "type": "local",  // ou "api"
        "editor": "MonIA",
        "size_gb": "5.2 GB",
        "params_tot": "7B",
        "ctx": 8192,
        "capabilities": ["chat", "tools"],
        "role": "assistant_generalist",
        "desc": "Description du modÃ¨le"
    }
}
```

**C'est tout !** Le modÃ¨le sera automatiquement :
- DÃ©tectÃ© comme Local ou API
- AffichÃ© dans les sÃ©lecteurs
- Utilisable dans Solo et Crew

---

## ğŸ“– Guide d'Utilisation Rapide

### 1. Chat Simple (Module 2)
```
1. SÃ©lectionner "InfÃ©rence & Arena" dans la sidebar
2. Onglet "Chat Interactif"
3. Choisir un modÃ¨le (ex: Qwen 2.5 1.5B)
4. Poser une question
```

### 2. Agent avec Outils (Module 4 - Solo)
```
1. SÃ©lectionner "Agent Lab" â†’ Mode Solo
2. Choisir un modÃ¨le (ex: Qwen 2.5 3B)
3. SÃ©lectionner les outils (ex: calculator, generate_chart)
4. Charger un prompt prÃ©dÃ©fini OU Ã©crire le vÃ´tre
5. Exemple : "CrÃ©e un graphique avec les ventes [100, 150, 200]"
```

### 3. Ã‰quipe Multi-Agents (Module 4 - Crew)
```
1. SÃ©lectionner "Agent Lab" â†’ Mode Crew
2. Charger un workflow prÃ©dÃ©fini (ex: "Pipeline analyse CSV")
3. Ajuster les modÃ¨les et outils si nÃ©cessaire
4. Lancer la mission
5. Observer la collaboration dans les logs
```

### 4. RAG sur Documents (Module 3)
```
1. SÃ©lectionner "RAG Knowledge"
2. Uploader un PDF/TXT
3. Attendre l'ingestion (quelques secondes)
4. Poser des questions sur le contenu
5. Les sources exactes sont affichÃ©es
```

---

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Consultez [CONTRIBUTING.md](CONTRIBUTING.md) pour :

- ğŸ› Signaler un bug
- âœ¨ Proposer une fonctionnalitÃ©
- ğŸ”§ Soumettre une Pull Request

**Processus :**
1. Fork le projet
2. CrÃ©er une branche (`git checkout -b feature/AmazingFeature`)
3. Commit les changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

**Code de conduite :** Soyez respectueux et constructif.

---

## ğŸ—ºï¸ Roadmap

### âœ… ComplÃ©tÃ© (DÃ©cembre 2025)
- [x] Support complet des modÃ¨les Mistral API
- [x] 9 outils agents (Email, CSV, DOCX, Charts, etc.)
- [x] Workflows multi-agents prÃ©dÃ©finis
- [x] SÃ©lection d'outils dynamique par agent
- [x] DÃ©tection unifiÃ©e API vs Local
- [x] Logs Crew nettoyÃ©s (codes ANSI)
- [x] Affichage des images dans le chat

### ğŸš€ Court Terme (Q1 2026)
- [ ] Support d'autres providers API (OpenAI, Anthropic)
- [ ] Ã‰valuation automatique des rÃ©ponses (LLM-as-a-Judge)
- [ ] Export des conversations en PDF/DOCX
- [ ] Mode comparaison side-by-side (Arena)
- [ ] Skills personnalisables (upload de SKILL.md)

### ğŸ›  Moyen Terme (Q2 2026)
- [ ] Dockerisation complÃ¨te
- [ ] API REST pour intÃ©gration externe
- [ ] Dashboard administrateur (gestion users)
- [ ] Support des modÃ¨les multimodaux (Vision)

### ğŸ”® Long Terme (2026+)
- [ ] Mode "LLM Council" (vote entre modÃ¨les)
- [ ] Auto-tuning des prompts systÃ¨me
- [ ] Marketplace de workflows Crew

---

## ğŸ“ Licence

Ce projet est distribuÃ© sous licence **MIT** - voir [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## ğŸ‘¤ Auteur

**AnaÃ«l Yahi**
Consultant en Transformation NumÃ©rique @ [Wavestone](https://www.wavestone.com/fr/)
SpÃ©cialitÃ© : IA GÃ©nÃ©rative

- LinkedIn : [AnaÃ«l Yahi](https://www.linkedin.com/in/ana%C3%ABl-yahi/)
- GitHub : [@Aliquanto3](https://github.com/Aliquanto3)

---

## ğŸ™ Remerciements

- **Wavestone** pour le soutien au projet
- **Alibaba (Qwen Team)** et **IBM (Granite)** pour leurs modÃ¨les SLM exceptionnels
- **Mistral AI** pour leur API performante
- **Ollama** pour le runtime local
- **LangChain & LangGraph** pour les abstractions agents
- **CrewAI** pour l'orchestration multi-agents

---

## â­ Support

Si ce projet vous est utile, n'hÃ©sitez pas Ã  :
- â­ Lui donner une Ã©toile sur GitHub
- ğŸ› Signaler des bugs ou proposer des amÃ©liorations
- ğŸ“¢ Le partager avec vos collÃ¨gues intÃ©ressÃ©s par l'IA locale

---

## ğŸ“Š Stats

![GitHub stars](https://img.shields.io/github/stars/Aliquanto3/wavelocalai?style=social)
![GitHub forks](https://img.shields.io/github/forks/Aliquanto3/wavelocalai?style=social)
![GitHub watchers](https://img.shields.io/github/watchers/Aliquanto3/wavelocalai?style=social)

---

## ğŸ“¸ Captures d'Ã‰cran

### Agent Solo avec GÃ©nÃ©ration de Graphique
```
[Image montrant : sÃ©lection d'outils, prompt, exÃ©cution, graphique affichÃ©]
```

### Crew Multi-Agents en Action
```
[Image montrant : 3 agents collaborant, logs de dÃ©lÃ©gation, rÃ©sultat final]
```

### Comparaison Local vs API
```
[Image montrant : mÃ©triques cÃ´te Ã  cÃ´te Qwen vs Mistral Large]
```

---

*DÃ©veloppÃ© avec â¤ï¸ pour la communautÃ© IA & Data de Wavestone*

**Version :** 2.0.0 (DÃ©cembre 2024)
**DerniÃ¨re mise Ã  jour :** 15/12/2024
